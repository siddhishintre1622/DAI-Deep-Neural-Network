{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a19e143-03fe-46a9-b7a7-ec90cc1ada1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65b7ab03-05af-4663-9cd1-1a713d01a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "parent_dir = os.path.abspath('..')\n",
    "sys.path.insert(0, parent_dir)\n",
    "from utils.helper import fn_plot_tf_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ac74348-aea5-432a-8155-7dce9445ebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 20\n",
    "LR_FACTOR = .2\n",
    "LR_PATIENCE = 5\n",
    "BUFFER_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bbfb662-bb43-4865-a627-9ffedcec0344",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpDir = os.path.join('..', 'input')\n",
    "outDir = '../output'\n",
    "modelDir = os.path.join('..', 'model')\n",
    "subDir = os.path.join('text_gen')\n",
    "fileName = 'shakespeare.txt'\n",
    "\n",
    "EPOCHS = 30\n",
    "ALPHA = .001\n",
    "TEST_SIZE = .2  \n",
    "\n",
    "\n",
    "BATCH_SIZE = 64 # default batch size fot tf\n",
    "RANDOM_STATE = 24 # for initialization ----- REMEMBER: to remove at the time of promotion to production\n",
    "np.random.RandomState(RANDOM_STATE) # Set Random Seed for reproducible results\n",
    "tf.random.set_seed(RANDOM_STATE) ######\n",
    "\n",
    "# parameters for Matplotlib\n",
    "params = {'legend.fontsize': 'large',\n",
    "          'figure.figsize': (15, 8),\n",
    "          'axes.labelsize': 'large',\n",
    "          'axes.titlesize':'x-large',\n",
    "          'xtick.labelsize':'large',\n",
    "          'ytick.labelsize':'large'\n",
    "         }\n",
    "\n",
    "CMAP = 'brg' # plt.cm.Spectral\n",
    "\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d6f3eb-0a1f-4b39-a58d-03039c044f60",
   "metadata": {},
   "source": [
    "## define data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6940d2d7-b4b1-4b7c-8c2a-a2adb106608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = os.path.join(inpDir, subDir, fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b957935-f6ad-4ff9-aa98-db3aa5295d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115395"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = open(filePath, 'rb').read().decode(encoding = 'utf-8') #The decode method in the context of bytes objects in Python is used to convert a byte sequence (binary data) into a string using a specific character encoding. \n",
    "\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5ed07bf-4a8a-480d-ba6c-2818e7d8da70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c437c63-30ce-4ae2-8a30-756dc47d830f",
   "metadata": {},
   "source": [
    "## character base modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b512d2cc-4752-4d89-ae47-8d12e5c1ff8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(set(text)) #  A sorted list of unique characters in the text.\n",
    "len(vocab) # all the characters  used in text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c16e90e-9358-4a55-be51-2d5e75d25772",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "char2idx = {u: i for i, u in enumerate(vocab)} # dict of index of character with character being key\n",
    "\n",
    "idx2char = np.array(vocab) # in array i can refer element by idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "476e7318-2611-4851-8a39-da5f54755004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115395,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int = np.array([char2idx [c] for c in text]) # will  have all sequence of integer which are index of those chars in `idx2char`\n",
    "text_as_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec36a007-14fa-4689-87a3-688eedecad50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'F'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(type(text_as_int))\n",
    "idx2char[text_as_int[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deb3a3c0-5cbe-443b-965f-91b30d3680e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 : F\n",
      "47 : i\n",
      "56 : r\n",
      "57 : s\n",
      "58 : t\n",
      "1 :  \n",
      "15 : C\n",
      "47 : i\n",
      "58 : t\n",
      "47 : i\n",
      "64 : z\n",
      "43 : e\n",
      "52 : n\n",
      "10 : :\n",
      "0 : \n",
      "\n",
      "14 : B\n",
      "43 : e\n",
      "44 : f\n",
      "53 : o\n",
      "56 : r\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100 # how many character will the data will work at a time\n",
    "\n",
    "example_per_epoch = len(text) // (seq_length + 1)\n",
    "# examples_per_epoch tells us how many training sequences can be created from the given text, based on the defined sequence length (seq_length).\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(20): #Prints the first 20 characters from the dataset along with their indices.\n",
    "    print(i.numpy(), end = ' : ')\n",
    "    print(idx2char[i.numpy()])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c9880c4-9100-4d2d-868a-a8f77d714175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59  1], shape=(101,), dtype=int32)\n",
      "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "tf.Tensor(\n",
      "[39 56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39 58 46 43 56  1\n",
      " 58 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47 57 46 12  0  0\n",
      " 13 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53 50 60 43 42  8\n",
      "  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47 56 57 58  6  1\n",
      " 63 53 59  1 49], shape=(101,), dtype=int32)\n",
      "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder = True)# Groups the dataset into sequences of length seq_length + 1 (100+1 in this case).\n",
    "# drop_remainder=True ensures only complete sequences are included.\n",
    "\n",
    "for item in sequences.take(2):\n",
    "    print(item)\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c4e2ee9-7f90-430f-9cc4-eca097c753e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11043"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "112852e9-0629-4f1b-bac0-3d74c15ffbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1] # first hundred characters\n",
    "    target_text = chunk[1:] # offset one as target\n",
    "    return input_text, target_text\n",
    "# Splits each sequence of length 101 into:\n",
    "# Input: First 100 characters.\n",
    "# Target: Next 100 characters (used as the target for prediction).\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f36871dd-a0b3-456e-a18d-7d63bf801395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The repr function in Python returns a string representation of an object that is designed to be unambiguous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6a28813-1c66-40d2-9f10-ce20730a550d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
      "'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you '\n",
      "'re all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n"
     ]
    }
   ],
   "source": [
    "for inp_ex, tar_ex in dataset.take(2):\n",
    "    print(repr(''.join(idx2char[inp_ex.numpy()])))\n",
    "    print(repr(''.join(idx2char[tar_ex.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32df767-4441-41ab-bc02-4ad6d966751f",
   "metadata": {},
   "source": [
    "#### preprocessing and fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da6a21cb-a60f-4e54-b947-b9179906b27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int32, name=None), TensorSpec(shape=(64, 100), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE,\n",
    "                                             drop_remainder = True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a426864f-4c7e-4efd-adc9-4310c0f92c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256 # generally 2 ^ (power) embedding works better\n",
    "rnn_unit = 1024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf82127-2ec5-4040-9ef8-79ca46232a8c",
   "metadata": {},
   "source": [
    "## preparing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f674dbfb-1003-4ebb-93f0-33d230936c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size,\n",
    "                embedding_dim,\n",
    "                rnn_units,\n",
    "                batch_size = BATCH_SIZE):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape = (None, ), batch_size = batch_size),\n",
    "        \n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "\n",
    "        tf.keras.layers.GRU(rnn_units, return_sequences = True,\n",
    "                           stateful = True,\n",
    "                          recurrent_initializer = 'glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1792ec1-e5a5-4c91-825c-71619e5ce522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,938,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,625</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m16,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)       │     \u001b[38;5;34m3,938,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)         │        \u001b[38;5;34m66,625\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,021,569</span> (15.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,021,569\u001b[0m (15.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,021,569</span> (15.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,021,569\u001b[0m (15.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_unit, batch_size = BATCH_SIZE)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5badc3de-0f42-4628-bb2c-6ffb602e8326",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### unit testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "acc0d57e-14f2-428c-b118-a20a0a84ec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit testing:~ checkin gif the model is working or not\n",
    "for inp_ex, tar_ex in dataset.take(1):\n",
    "    ex_pred = model(inp_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "959df71b-c306-4bf7-9061-e93cf1aba5d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 100, 65])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_pred.shape # 64: batch size, 100: time step, : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c79b73a8-f204-4075-b019-ee6594bae26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### why we sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c802ad46-8d8e-4a89-855b-68214855ad07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "sample_indices = tf.random.categorical(ex_pred[0], num_samples = 1)\n",
    "print(sample_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9ba516c-ca47-40c9-a50c-a80392c39df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices = tf.squeeze(sample_indices, axis = -1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7825d10e-5be5-4baf-8808-ae6417604a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0d6c58ec-375c-46b0-be7e-617b6ef9f46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  7, 41, 15, 39, 39, 10, 36, 52, 19, 31, 43, 61, 16, 49,  3, 44,\n",
       "        7,  5, 30, 43, 14, 16, 36, 21, 61, 53, 25, 64, 49, 53, 60, 27, 48,\n",
       "       45, 35, 12, 53, 38, 26, 12, 35, 49,  1, 27, 58, 23, 59, 10, 15,  5,\n",
       "       46, 43, 48, 57, 23, 60, 15, 32, 53, 21,  8,  1, 55, 52, 27, 56, 59,\n",
       "       48, 55, 57,  0, 16, 48, 20, 36, 22, 55, 21, 55, 23, 30, 16, 32,  0,\n",
       "       50, 23,  4, 46, 45, 63, 28,  3,  5, 56, 64, 11, 57, 43,  4],\n",
       "      dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\",-cCaa:XnGSewDk$f-'ReBDXIwoMzkovOjgW?oZN?Wk OtKu:C'hejsKvCToI. qnOrujqs\\nDjHXJqIqKRDT\\nlK&hgyP$'rz;se&\"\n"
     ]
    }
   ],
   "source": [
    "display(sample_indices)\n",
    "print(repr(''.join(idx2char[sample_indices])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5f3814-8413-49a0-a87a-9cb824e699d1",
   "metadata": {},
   "source": [
    "### training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eaba1080-dfc2-44c8-a3a6-66f66b1d1b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "model.compile (optimizer = 'adam',\n",
    "               loss = loss_fn,\n",
    "               metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "30f1e8b8-77f5-4552-a199-a596630e6a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "chkPath = os.path.join(modelDir, subDir)\n",
    "chkPtPrefix = os.path.join(chkPath, 'chkpt_{epoch}.keras') # chkPtPrefix: telling how you should make name of the file i save\n",
    "\n",
    "chkpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath = chkPtPrefix ,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0fd7f6-7891-45fc-b4db-bd54ba73fcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m 73/172\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:38\u001b[0m 994ms/step - accuracy: 0.1736 - loss: 3.6055"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs = EPOCHS,\n",
    "                    callbacks = [chkpt_callback],\n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "eb6ae907-0b79-41c1-95fb-39cef7b71bb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m los_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory)\n\u001b[0;32m      2\u001b[0m fn_plot_tf_hist(loss_df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "los_df = pd.DataFrame(history.history)\n",
    "fn_plot_tf_hist(loss_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91512953-d257-4003-bf99-549539b6bf0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
